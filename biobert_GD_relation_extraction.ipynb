{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biobert_GD_relation_extraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["######**PubMed Preprocessing and Gene,Disease Masking**"],"metadata":{"id":"xtS7Up0zKAHv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ilwJeV9q0eRh","executionInfo":{"status":"ok","timestamp":1652504602744,"user_tz":-330,"elapsed":16695,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"32f3de78-433c-4c21-812d-5b6770593644"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/NLP/Genomatics Package/BioBert/biobert-pytorch/relation-extraction')"],"metadata":{"id":"P827aovKvWW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VlU62mXtmC3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652504960257,"user_tz":-330,"elapsed":994,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"c0ec39a5-8865-4fdc-ddac-6a7968ea2dee"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n","  InsecureRequestWarning)\n"]}],"source":["#We extract the pubmed document in BioCJSON format\n","import urllib3\n","import json\n","import csv\n","import requests\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from itertools import combinations\n","\n","pmcid = 'PMC2837563'\n","\n","http = urllib3.PoolManager()\n","\n","r = http.request('GET', f'https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocjson?pmcids={pmcid}')\n","data = json.loads(r.data.decode('utf-8'))\n","#data = json.dumps(data, indent=4)"]},{"cell_type":"code","source":["#os.chdir('BioBert/biobert-pytorch/datasets/RE/GAD')"],"metadata":{"id":"n_jt60ZHpxK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1 = open('testset/test.tsv', 'w')\n","tsv_writer_1 = csv.writer(f1, delimiter='\\t')\n","tsv_writer_1.writerow(['index', 'sentence'])\n","f2 = open('pubtator_outputs/pub_original_sentences.tsv', 'w')\n","tsv_writer_2 = csv.writer(f2, delimiter='\\t')\n","tsv_writer_2.writerow(['index', 'sentence', 'entity_1', 'entity_2'])"],"metadata":{"id":"BGMzIz-I2BYs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652504964959,"user_tz":-330,"elapsed":368,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"fb584af1-8680-4e5d-feaf-c51435449ad0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["sentence_index = 0\n","sentence_entities = {}\n","for i in data['passages']:\n","  if i['infons']['section_type'] != 'TABLE':\n","    #filter the table segment\n","    text = i['text']\n","    offset = i['offset']\n","    annotations = i['annotations']\n","\n","    annotations = sorted(annotations, key = lambda x: x['locations'][0]['offset'])\n","    #Filter to only include gene-disease annotations\n","    annotations = [annotation for annotation in annotations if ((annotation['infons']['type']=='Gene') or (annotation['infons']['type']=='Disease'))]\n","    #List all possible combinations of annotations\n","    annots_combinations = list(combinations(annotations, 2))\n","    #Filter combinations to only include gene-disease combinations\n","    annots_combinations = [annots for annots in annots_combinations if annots[0]['infons']['type'] != annots[1]['infons']['type']]\n","\n","\n","    #processing sentences\n","    sentences = text.split('. ')\n","    sentence_offset = {}\n","    sentence_len = {}\n","    prev_sent_offset = offset\n","\n","    for sentence in sentences:\n","\n","      sentence_offset[sentence] = prev_sent_offset\n","      current_sentence_offset = prev_sent_offset\n","      sentence_len[sentence] = len(sentence)\n","      current_sentence_len = len(sentence)\n","      prev_sent_offset += len(sentence) + 2\n","      \n","\n","      #Point to note: Duplicate sentences for as many combinations as present. \n","      for annots in annots_combinations:\n","        difference = 0\n","        current_sentence = sentence\n","        #sort the tuple\n","        annots = sorted(annots, key = lambda x: x['locations'][0]['offset'])\n","\n","        entity_1 = annots[0]\n","        entity_2 = annots[1]\n","        \n","        entity_1_offset = entity_1['locations'][0]['offset']\n","        entity_2_offset = entity_2['locations'][0]['offset']\n","\n","        entity_1_dist = entity_1_offset - current_sentence_offset\n","        entity_2_dist = entity_2_offset - current_sentence_offset\n","\n","        if (0 <= entity_1_dist <= ((current_sentence_len - len(entity_1['text'])) + 1)) and (0 <= entity_2_dist <= ((current_sentence_len - len(entity_2['text'])) + 1)):\n","          #the pair of annotations fall within the sentence\n","          sentence_entities[sentence_index] = (entity_1['text'], entity_2['text'])\n","\n","          entity_1_type = entity_1['infons']['type']\n","          entity_1_length = entity_1['locations'][0]['length']\n","          temp = '@'+ entity_1_type +'$'\n","          entity_1_final_off = entity_1_dist \n","          current_sentence = current_sentence[:entity_1_final_off] + \"@\" + entity_1_type + \"$\" + current_sentence[(entity_1_final_off + entity_1_length):]\n","          difference += (entity_1_length - len(temp))\n","\n","          entity_2_type = entity_2['infons']['type']\n","          entity_2_length = entity_2['locations'][0]['length']\n","          temp = '@'+ entity_2_type +'$'\n","          entity_2_final_off = entity_2_dist - (difference)\n","          current_sentence = current_sentence[:entity_2_final_off] + \"@\" + entity_2_type + \"$\" + current_sentence[(entity_2_final_off + entity_2_length):]\n","          difference += (entity_2_length - len(temp))\n","          tsv_writer_1.writerow([sentence_index, current_sentence])\n","          tsv_writer_2.writerow([sentence_index, sentence, entity_1['text'], entity_2['text']])\n","          sentence_index += 1"],"metadata":{"id":"IWtnweo4sJH2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["######**BioBERT Training**"],"metadata":{"id":"VDySKdOJrGig"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7486,"status":"ok","timestamp":1652505067914,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"},"user_tz":-330},"id":"jFGqcq3Sypk2","outputId":"aebc12f4-5d32-4f97-9a74-baf607af2ad4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 5.4 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 54.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.64.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 27.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 54.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (3.0.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=03e8585623dfde8a3f96f9424cc9abe6c98d88efe8d101c630a8b3a390aa6c1f\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.0\n"]}],"source":["!pip install transformers==3.0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiuwaer4zzr9"},"outputs":[],"source":["#!git clone https://github.com/dmis-lab/biobert-pytorch.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKLaP9Zfz6hZ"},"outputs":[],"source":["#os.chdir('/content/drive/MyDrive/NLP/Genomatics Package/BioBert/biobert-pytorch')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4367,"status":"ok","timestamp":1652500429035,"user":{"displayName":"18PD23 - PARKAVI S","userId":"01984714472592027023"},"user_tz":-330},"id":"t2221d9V0BA4","outputId":"633a73af-2b6d-436e-bf69-2288254f0d49"},"outputs":[{"output_type":"stream","name":"stdout","text":["BIOBERT_DATA not set; downloading to default path ('data').\n","--2022-05-14 03:51:56--  https://docs.google.com/uc?export=download&confirm=t&id=1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j\n","Resolving docs.google.com (docs.google.com)... 108.177.119.101, 108.177.119.102, 108.177.119.138, ...\n","Connecting to docs.google.com (docs.google.com)|108.177.119.101|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-10-20-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qu9qdum5f8s73039mq83p7pc9t15mela/1652500275000/13799006341648886493/*/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2022-05-14 03:51:56--  https://doc-10-20-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qu9qdum5f8s73039mq83p7pc9t15mela/1652500275000/13799006341648886493/*/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download\n","Resolving doc-10-20-docs.googleusercontent.com (doc-10-20-docs.googleusercontent.com)... 173.194.69.132, 2a00:1450:4013:c04::84\n","Connecting to doc-10-20-docs.googleusercontent.com (doc-10-20-docs.googleusercontent.com)|173.194.69.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29610233 (28M) [application/x-gzip]\n","Saving to: ‘./data.tar.gz’\n","\n","./data.tar.gz       100%[===================>]  28.24M  66.4MB/s    in 0.4s    \n","\n","2022-05-14 03:51:57 (66.4 MB/s) - ‘./data.tar.gz’ saved [29610233/29610233]\n","\n","datasets/\n","datasets/RE/\n","datasets/RE/GAD/\n","datasets/RE/GAD/6/\n","datasets/RE/GAD/6/test.tsv\n","datasets/RE/GAD/6/dev.tsv\n","datasets/RE/GAD/6/train.tsv\n","datasets/RE/GAD/7/\n","datasets/RE/GAD/7/test.tsv\n","datasets/RE/GAD/7/dev.tsv\n","datasets/RE/GAD/7/train.tsv\n","datasets/RE/GAD/5/\n","datasets/RE/GAD/5/test.tsv\n","datasets/RE/GAD/5/dev.tsv\n","datasets/RE/GAD/5/train.tsv\n","datasets/RE/GAD/8/\n","datasets/RE/GAD/8/test.tsv\n","datasets/RE/GAD/8/dev.tsv\n","datasets/RE/GAD/8/train.tsv\n","datasets/RE/GAD/4/\n","datasets/RE/GAD/4/test.tsv\n","datasets/RE/GAD/4/dev.tsv\n","datasets/RE/GAD/4/train.tsv\n","datasets/RE/GAD/1/\n","datasets/RE/GAD/1/test.tsv\n","datasets/RE/GAD/1/dev.tsv\n","datasets/RE/GAD/1/train.tsv\n","datasets/RE/GAD/2/\n","datasets/RE/GAD/2/test.tsv\n","datasets/RE/GAD/2/dev.tsv\n","datasets/RE/GAD/2/train.tsv\n","datasets/RE/GAD/3/\n","datasets/RE/GAD/3/test.tsv\n","datasets/RE/GAD/3/dev.tsv\n","datasets/RE/GAD/3/train.tsv\n","datasets/RE/GAD/9/\n","datasets/RE/GAD/9/test.tsv\n","datasets/RE/GAD/9/dev.tsv\n","datasets/RE/GAD/9/train.tsv\n","datasets/RE/GAD/10/\n","datasets/RE/GAD/10/test.tsv\n","datasets/RE/GAD/10/dev.tsv\n","datasets/RE/GAD/10/train.tsv\n","datasets/RE/euadr/\n","datasets/RE/euadr/6/\n","datasets/RE/euadr/6/test.tsv\n","datasets/RE/euadr/6/dev.tsv\n","datasets/RE/euadr/6/train.tsv\n","datasets/RE/euadr/7/\n","datasets/RE/euadr/7/test.tsv\n","datasets/RE/euadr/7/dev.tsv\n","datasets/RE/euadr/7/train.tsv\n","datasets/RE/euadr/5/\n","datasets/RE/euadr/5/test.tsv\n","datasets/RE/euadr/5/dev.tsv\n","datasets/RE/euadr/5/train.tsv\n","datasets/RE/euadr/8/\n","datasets/RE/euadr/8/test.tsv\n","datasets/RE/euadr/8/dev.tsv\n","datasets/RE/euadr/8/train.tsv\n","datasets/RE/euadr/4/\n","datasets/RE/euadr/4/test.tsv\n","datasets/RE/euadr/4/dev.tsv\n","datasets/RE/euadr/4/train.tsv\n","datasets/RE/euadr/1/\n","datasets/RE/euadr/1/test.tsv\n","datasets/RE/euadr/1/dev.tsv\n","datasets/RE/euadr/1/train.tsv\n","datasets/RE/euadr/2/\n","datasets/RE/euadr/2/test.tsv\n","datasets/RE/euadr/2/dev.tsv\n","datasets/RE/euadr/2/train.tsv\n","datasets/RE/euadr/3/\n","datasets/RE/euadr/3/test.tsv\n","datasets/RE/euadr/3/dev.tsv\n","datasets/RE/euadr/3/train.tsv\n","datasets/RE/euadr/9/\n","datasets/RE/euadr/9/test.tsv\n","datasets/RE/euadr/9/dev.tsv\n","datasets/RE/euadr/9/train.tsv\n","datasets/RE/euadr/10/\n","datasets/RE/euadr/10/test.tsv\n","datasets/RE/euadr/10/dev.tsv\n","datasets/RE/euadr/10/train.tsv\n","datasets/QA/\n","datasets/QA/BioASQ/\n","datasets/QA/BioASQ/6B1_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-7b.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-5b-4.json\n","datasets/QA/BioASQ/5B3_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-4b-2.json\n","datasets/QA/BioASQ/4B1_golden.json\n","datasets/QA/BioASQ/BioASQ-train-yesno-7b.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-5b-5.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-5b-2.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-6b-2.json\n","datasets/QA/BioASQ/4B4_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-6b-3.json\n","datasets/QA/BioASQ/6B3_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-5b-3.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-6b-5.json\n","datasets/QA/BioASQ/BioASQ-test-yesno-7b.json\n","datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-4b-1.json\n","datasets/QA/BioASQ/6B5_golden.json\n","datasets/QA/BioASQ/5B1_golden.json\n","datasets/QA/BioASQ/4B5_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-4b-3.json\n","datasets/QA/BioASQ/7B_golden.json\n","datasets/QA/BioASQ/5B4_golden.json\n","datasets/QA/BioASQ/BioASQ-train-factoid-6b.json\n","datasets/QA/BioASQ/BioASQ-train-factoid-7b.json\n","datasets/QA/BioASQ/SHA1.txt\n","datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json\n","datasets/QA/BioASQ/BioASQ-train-factoid-5b.json\n","datasets/QA/BioASQ/5B2_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-6b-4.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-5b-1.json\n","datasets/QA/BioASQ/4B3_golden.json\n","datasets/QA/BioASQ/6B2_golden.json\n","datasets/QA/BioASQ/4B2_golden.json\n","datasets/QA/BioASQ/6B4_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-4b-5.json\n","datasets/QA/BioASQ/5B5_golden.json\n","datasets/QA/BioASQ/BioASQ-test-factoid-4b-4.json\n","datasets/NER/\n","datasets/NER/linnaeus/\n","datasets/NER/linnaeus/devel.tsv\n","datasets/NER/linnaeus/test.tsv\n","datasets/NER/linnaeus/train_dev.tsv\n","datasets/NER/linnaeus/train.tsv\n","datasets/NER/BC2GM/\n","datasets/NER/BC2GM/devel.tsv\n","datasets/NER/BC2GM/test.tsv\n","datasets/NER/BC2GM/train_dev.tsv\n","datasets/NER/BC2GM/train.tsv\n","datasets/NER/BC5CDR-disease/\n","datasets/NER/BC5CDR-disease/devel.tsv\n","datasets/NER/BC5CDR-disease/test.tsv\n","datasets/NER/BC5CDR-disease/train_dev.tsv\n","datasets/NER/BC5CDR-disease/train.tsv\n","datasets/NER/NCBI-disease/\n","datasets/NER/NCBI-disease/devel.tsv\n","datasets/NER/NCBI-disease/test.tsv\n","datasets/NER/NCBI-disease/train_dev.tsv\n","datasets/NER/NCBI-disease/train.tsv\n","datasets/NER/s800/\n","datasets/NER/s800/devel.tsv\n","datasets/NER/s800/test.tsv\n","datasets/NER/s800/train_dev.tsv\n","datasets/NER/s800/train.tsv\n","datasets/NER/BC5CDR-chem/\n","datasets/NER/BC5CDR-chem/devel.tsv\n","datasets/NER/BC5CDR-chem/test.tsv\n","datasets/NER/BC5CDR-chem/train_dev.tsv\n","datasets/NER/BC5CDR-chem/train.tsv\n","datasets/NER/JNLPBA/\n","datasets/NER/JNLPBA/devel.tsv\n","datasets/NER/JNLPBA/test.tsv\n","datasets/NER/JNLPBA/train_dev.tsv\n","datasets/NER/JNLPBA/train.tsv\n","datasets/NER/BC4CHEMD/\n","datasets/NER/BC4CHEMD/devel.tsv\n","datasets/NER/BC4CHEMD/test.tsv\n","datasets/NER/BC4CHEMD/train_dev.tsv\n","datasets/NER/BC4CHEMD/train.tsv\n","BioBERT dataset download done!\n"]}],"source":["!bash ./download.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10022,"status":"ok","timestamp":1652500439053,"user":{"displayName":"18PD23 - PARKAVI S","userId":"01984714472592027023"},"user_tz":-330},"id":"FwRsw7fH0Zx0","outputId":"25bf58f6-f29b-4dbe-ee7f-5d358a612780"},"outputs":[{"output_type":"stream","name":"stdout","text":["*****  euadr  Preprocessing Start *****\n","*****  euadr  Preprocessing Done *****\n","*****  GAD  Preprocessing Start *****\n","*****  GAD  Preprocessing Done *****\n"]}],"source":["!bash ./preprocess.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1652505084082,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"},"user_tz":-330},"id":"_xJ097TV0gch","outputId":"ee46f029-3019-4d34-feb7-02bd4341633e"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: SAVE_DIR=./output\n","env: DATA=\"GAD\"\n","env: SPLIT=\"1\"\n","env: DATA_DIR=../datasets/RE/GAD/1\n","env: ENTITY=${DATA}-${SPLIT}\n","env: MAX_LENGTH=128\n","env: BATCH_SIZE=32\n","env: NUM_EPOCHS=3\n","env: SAVE_STEPS=1000\n","env: SEED=1\n"]}],"source":["%env SAVE_DIR=./output\n","%env DATA=\"GAD\"\n","%env SPLIT=\"1\"\n","%env DATA_DIR=../datasets/RE/GAD/1\n","%env ENTITY=${DATA}-${SPLIT}\n","\n","%env MAX_LENGTH=128\n","%env BATCH_SIZE=32\n","%env NUM_EPOCHS=3\n","%env SAVE_STEPS=1000\n","%env SEED=1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652500439053,"user":{"displayName":"18PD23 - PARKAVI S","userId":"01984714472592027023"},"user_tz":-330},"id":"S0JnSYSz14Ce","outputId":"e1db3f55-5c3d-457b-d915-911ae37bc392"},"outputs":[{"output_type":"stream","name":"stdout","text":["DATA_DIR\n"]}],"source":["!echo DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6Ze1gi_1Gfl","outputId":"ee1128f4-5956-416a-8b58-f8ffe1c7fda9","executionInfo":{"status":"ok","timestamp":1652505447935,"user_tz":-330,"elapsed":360073,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["05/14/2022 05:11:34 - INFO - transformers.training_args -   PyTorch: setting up devices\n","05/14/2022 05:11:34 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp7mihet3v\n","Downloading: 100% 313/313 [00:00<00:00, 272kB/s]\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/config.json in cache at /root/.cache/torch/transformers/efc161c68d589c7960ab5463ed06a47d75d1ec73b2c31938de0ff797f76892dd.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/efc161c68d589c7960ab5463ed06a47d75d1ec73b2c31938de0ff797f76892dd.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n","05/14/2022 05:11:35 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/config.json from cache at /root/.cache/torch/transformers/efc161c68d589c7960ab5463ed06a47d75d1ec73b2c31938de0ff797f76892dd.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n","05/14/2022 05:11:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","05/14/2022 05:11:35 - INFO - transformers.tokenization_utils_base -   Model name 'dmis-lab/biobert-base-cased-v1.1' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'dmis-lab/biobert-base-cased-v1.1' is a path, a model identifier, or url to a directory containing tokenizer files.\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpq_p6mehd\n","Downloading: 100% 213k/213k [00:00<00:00, 2.45MB/s]\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/vocab.txt in cache at /root/.cache/torch/transformers/a6d2d795bddbd9841e0ccd4a2f51c5b412116fda79488f6ffed7979e7ea9ef36.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","05/14/2022 05:11:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/a6d2d795bddbd9841e0ccd4a2f51c5b412116fda79488f6ffed7979e7ea9ef36.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","05/14/2022 05:11:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/vocab.txt from cache at /root/.cache/torch/transformers/a6d2d795bddbd9841e0ccd4a2f51c5b412116fda79488f6ffed7979e7ea9ef36.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","05/14/2022 05:11:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/added_tokens.json from cache at None\n","05/14/2022 05:11:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/special_tokens_map.json from cache at None\n","05/14/2022 05:11:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/tokenizer_config.json from cache at None\n","05/14/2022 05:11:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/tokenizer.json from cache at None\n","05/14/2022 05:11:37 - INFO - transformers.data.datasets.glue -   Loading features from cached file ../datasets/RE/GAD/1/cached_train_BertTokenizer_128_sst-2 [took 0.995 s]\n","05/14/2022 05:11:38 - INFO - transformers.data.datasets.glue -   Loading features from cached file ../datasets/RE/GAD/1/cached_test_BertTokenizer_128_sst-2 [took 0.212 s]\n","05/14/2022 05:11:38 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/${DATA}-${SPLIT}', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=True, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=44, logging_dir='runs/May14_05-11-34_b093b39aeb65', logging_first_step=False, logging_steps=500, save_steps=1000, save_total_limit=None, no_cuda=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, dataloader_drop_last=False)\n","05/14/2022 05:11:38 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpcdpzl260\n","Downloading: 100% 433/433 [00:00<00:00, 347kB/s]\n","05/14/2022 05:11:38 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json in cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","05/14/2022 05:11:38 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","05/14/2022 05:11:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","05/14/2022 05:11:38 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"sst-2\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","05/14/2022 05:11:38 - INFO - transformers.file_utils -   https://cdn.huggingface.co/dmis-lab/biobert-base-cased-v1.1/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmprh0c5cy2\n","Downloading: 100% 436M/436M [00:07<00:00, 57.6MB/s]\n","05/14/2022 05:11:46 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/dmis-lab/biobert-base-cased-v1.1/pytorch_model.bin in cache at /root/.cache/torch/transformers/685bf1692895fda434bf7c6a6eeab569b8b540cb6ba84268fc85fa13a1a7d748.7108af90c9002a82d12d4a007d2f2525c8d855c2bb9b10e701177769136bc7eb\n","05/14/2022 05:11:46 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/685bf1692895fda434bf7c6a6eeab569b8b540cb6ba84268fc85fa13a1a7d748.7108af90c9002a82d12d4a007d2f2525c8d855c2bb9b10e701177769136bc7eb\n","05/14/2022 05:11:46 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/dmis-lab/biobert-base-cased-v1.1/pytorch_model.bin from cache at /root/.cache/torch/transformers/685bf1692895fda434bf7c6a6eeab569b8b540cb6ba84268fc85fa13a1a7d748.7108af90c9002a82d12d4a007d2f2525c8d855c2bb9b10e701177769136bc7eb\n","05/14/2022 05:11:49 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","05/14/2022 05:11:49 - WARNING - transformers.modeling_utils -   Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","05/14/2022 05:12:04 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n","05/14/2022 05:12:04 - INFO - transformers.trainer -   ***** Running training *****\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Num examples = 4796\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Num Epochs = 3\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Instantaneous batch size per device = 32\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\n","05/14/2022 05:12:04 - INFO - transformers.trainer -     Total optimization steps = 450\n","Epoch:   0% 0/3 [00:00<?, ?it/s]\n","Iteration:   0% 0/150 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/150 [00:00<02:08,  1.16it/s]\u001b[A\n","Iteration:   1% 2/150 [00:01<01:43,  1.43it/s]\u001b[A\n","Iteration:   2% 3/150 [00:02<01:37,  1.51it/s]\u001b[A\n","Iteration:   3% 4/150 [00:02<01:32,  1.58it/s]\u001b[A\n","Iteration:   3% 5/150 [00:03<01:30,  1.60it/s]\u001b[A\n","Iteration:   4% 6/150 [00:03<01:28,  1.62it/s]\u001b[A\n","Iteration:   5% 7/150 [00:04<01:27,  1.64it/s]\u001b[A\n","Iteration:   5% 8/150 [00:05<01:26,  1.65it/s]\u001b[A\n","Iteration:   6% 9/150 [00:05<01:25,  1.65it/s]\u001b[A\n","Iteration:   7% 10/150 [00:06<01:24,  1.65it/s]\u001b[A\n","Iteration:   7% 11/150 [00:06<01:25,  1.62it/s]\u001b[A\n","Iteration:   8% 12/150 [00:07<01:25,  1.62it/s]\u001b[A\n","Iteration:   9% 13/150 [00:08<01:24,  1.62it/s]\u001b[A\n","Iteration:   9% 14/150 [00:08<01:24,  1.61it/s]\u001b[A\n","Iteration:  10% 15/150 [00:09<01:22,  1.63it/s]\u001b[A\n","Iteration:  11% 16/150 [00:09<01:21,  1.64it/s]\u001b[A\n","Iteration:  11% 17/150 [00:10<01:20,  1.64it/s]\u001b[A\n","Iteration:  12% 18/150 [00:11<01:20,  1.63it/s]\u001b[A\n","Iteration:  13% 19/150 [00:11<01:21,  1.61it/s]\u001b[A\n","Iteration:  13% 20/150 [00:12<01:20,  1.62it/s]\u001b[A\n","Iteration:  14% 21/150 [00:13<01:19,  1.62it/s]\u001b[A\n","Iteration:  15% 22/150 [00:13<01:18,  1.63it/s]\u001b[A\n","Iteration:  15% 23/150 [00:14<01:17,  1.63it/s]\u001b[A\n","Iteration:  16% 24/150 [00:14<01:17,  1.64it/s]\u001b[A\n","Iteration:  17% 25/150 [00:15<01:16,  1.63it/s]\u001b[A\n","Iteration:  17% 26/150 [00:16<01:16,  1.63it/s]\u001b[A\n","Iteration:  18% 27/150 [00:16<01:16,  1.60it/s]\u001b[A\n","Iteration:  19% 28/150 [00:17<01:15,  1.61it/s]\u001b[A\n","Iteration:  19% 29/150 [00:18<01:16,  1.58it/s]\u001b[A\n","Iteration:  20% 30/150 [00:18<01:15,  1.59it/s]\u001b[A\n","Iteration:  21% 31/150 [00:19<01:14,  1.59it/s]\u001b[A\n","Iteration:  21% 32/150 [00:19<01:13,  1.60it/s]\u001b[A\n","Iteration:  22% 33/150 [00:20<01:13,  1.60it/s]\u001b[A\n","Iteration:  23% 34/150 [00:21<01:12,  1.59it/s]\u001b[A\n","Iteration:  23% 35/150 [00:21<01:12,  1.58it/s]\u001b[A\n","Iteration:  24% 36/150 [00:22<01:11,  1.59it/s]\u001b[A\n","Iteration:  25% 37/150 [00:23<01:10,  1.60it/s]\u001b[A\n","Iteration:  25% 38/150 [00:23<01:10,  1.59it/s]\u001b[A\n","Iteration:  26% 39/150 [00:24<01:09,  1.59it/s]\u001b[A\n","Iteration:  27% 40/150 [00:24<01:10,  1.57it/s]\u001b[A\n","Iteration:  27% 41/150 [00:25<01:09,  1.57it/s]\u001b[A\n","Iteration:  28% 42/150 [00:26<01:10,  1.54it/s]\u001b[A\n","Iteration:  29% 43/150 [00:26<01:09,  1.53it/s]\u001b[A\n","Iteration:  29% 44/150 [00:27<01:09,  1.53it/s]\u001b[A\n","Iteration:  30% 45/150 [00:28<01:09,  1.51it/s]\u001b[A\n","Iteration:  31% 46/150 [00:28<01:07,  1.54it/s]\u001b[A\n","Iteration:  31% 47/150 [00:29<01:08,  1.50it/s]\u001b[A\n","Iteration:  32% 48/150 [00:30<01:08,  1.50it/s]\u001b[A\n","Iteration:  33% 49/150 [00:30<01:06,  1.51it/s]\u001b[A\n","Iteration:  33% 50/150 [00:31<01:05,  1.53it/s]\u001b[A\n","Iteration:  34% 51/150 [00:32<01:04,  1.54it/s]\u001b[A\n","Iteration:  35% 52/150 [00:32<01:03,  1.55it/s]\u001b[A\n","Iteration:  35% 53/150 [00:33<01:02,  1.54it/s]\u001b[A\n","Iteration:  36% 54/150 [00:34<01:02,  1.52it/s]\u001b[A\n","Iteration:  37% 55/150 [00:34<01:01,  1.54it/s]\u001b[A\n","Iteration:  37% 56/150 [00:35<01:02,  1.51it/s]\u001b[A\n","Iteration:  38% 57/150 [00:36<01:00,  1.53it/s]\u001b[A\n","Iteration:  39% 58/150 [00:36<01:00,  1.53it/s]\u001b[A\n","Iteration:  39% 59/150 [00:37<00:59,  1.53it/s]\u001b[A\n","Iteration:  40% 60/150 [00:38<00:58,  1.55it/s]\u001b[A\n","Iteration:  41% 61/150 [00:38<00:57,  1.56it/s]\u001b[A\n","Iteration:  41% 62/150 [00:39<00:56,  1.55it/s]\u001b[A\n","Iteration:  42% 63/150 [00:40<00:57,  1.53it/s]\u001b[A\n","Iteration:  43% 64/150 [00:40<00:56,  1.53it/s]\u001b[A\n","Iteration:  43% 65/150 [00:41<00:55,  1.54it/s]\u001b[A\n","Iteration:  44% 66/150 [00:41<00:54,  1.54it/s]\u001b[A\n","Iteration:  45% 67/150 [00:42<00:53,  1.55it/s]\u001b[A\n","Iteration:  45% 68/150 [00:43<00:52,  1.56it/s]\u001b[A\n","Iteration:  46% 69/150 [00:43<00:51,  1.56it/s]\u001b[A\n","Iteration:  47% 70/150 [00:44<00:51,  1.57it/s]\u001b[A\n","Iteration:  47% 71/150 [00:45<00:50,  1.57it/s]\u001b[A\n","Iteration:  48% 72/150 [00:45<00:49,  1.58it/s]\u001b[A\n","Iteration:  49% 73/150 [00:46<00:48,  1.58it/s]\u001b[A\n","Iteration:  49% 74/150 [00:47<00:47,  1.59it/s]\u001b[A\n","Iteration:  50% 75/150 [00:47<00:47,  1.59it/s]\u001b[A\n","Iteration:  51% 76/150 [00:48<00:46,  1.58it/s]\u001b[A\n","Iteration:  51% 77/150 [00:48<00:46,  1.58it/s]\u001b[A\n","Iteration:  52% 78/150 [00:49<00:45,  1.58it/s]\u001b[A\n","Iteration:  53% 79/150 [00:50<00:45,  1.57it/s]\u001b[A\n","Iteration:  53% 80/150 [00:50<00:44,  1.57it/s]\u001b[A\n","Iteration:  54% 81/150 [00:51<00:43,  1.58it/s]\u001b[A\n","Iteration:  55% 82/150 [00:52<00:43,  1.57it/s]\u001b[A\n","Iteration:  55% 83/150 [00:52<00:42,  1.57it/s]\u001b[A\n","Iteration:  56% 84/150 [00:53<00:42,  1.56it/s]\u001b[A\n","Iteration:  57% 85/150 [00:54<00:41,  1.56it/s]\u001b[A\n","Iteration:  57% 86/150 [00:54<00:41,  1.55it/s]\u001b[A\n","Iteration:  58% 87/150 [00:55<00:40,  1.55it/s]\u001b[A\n","Iteration:  59% 88/150 [00:55<00:40,  1.55it/s]\u001b[A\n","Iteration:  59% 89/150 [00:56<00:39,  1.54it/s]\u001b[A\n","Iteration:  60% 90/150 [00:57<00:38,  1.54it/s]\u001b[A\n","Iteration:  61% 91/150 [00:57<00:38,  1.54it/s]\u001b[A\n","Iteration:  61% 92/150 [00:58<00:37,  1.54it/s]\u001b[A\n","Iteration:  62% 93/150 [00:59<00:36,  1.54it/s]\u001b[A\n","Iteration:  63% 94/150 [00:59<00:36,  1.54it/s]\u001b[A\n","Iteration:  63% 95/150 [01:00<00:35,  1.54it/s]\u001b[A\n","Iteration:  64% 96/150 [01:01<00:34,  1.54it/s]\u001b[A\n","Iteration:  65% 97/150 [01:01<00:34,  1.54it/s]\u001b[A\n","Iteration:  65% 98/150 [01:02<00:33,  1.54it/s]\u001b[A\n","Iteration:  66% 99/150 [01:03<00:33,  1.54it/s]\u001b[A\n","Iteration:  67% 100/150 [01:03<00:32,  1.54it/s]\u001b[A\n","Iteration:  67% 101/150 [01:04<00:31,  1.53it/s]\u001b[A\n","Iteration:  68% 102/150 [01:05<00:31,  1.53it/s]\u001b[A\n","Iteration:  69% 103/150 [01:05<00:30,  1.53it/s]\u001b[A\n","Iteration:  69% 104/150 [01:06<00:30,  1.53it/s]\u001b[A\n","Iteration:  70% 105/150 [01:07<00:29,  1.52it/s]\u001b[A\n","Iteration:  71% 106/150 [01:07<00:28,  1.52it/s]\u001b[A\n","Iteration:  71% 107/150 [01:08<00:28,  1.52it/s]\u001b[A\n","Iteration:  72% 108/150 [01:09<00:27,  1.51it/s]\u001b[A\n","Iteration:  73% 109/150 [01:09<00:27,  1.52it/s]\u001b[A\n","Iteration:  73% 110/150 [01:10<00:26,  1.51it/s]\u001b[A\n","Iteration:  74% 111/150 [01:11<00:25,  1.51it/s]\u001b[A\n","Iteration:  75% 112/150 [01:11<00:25,  1.51it/s]\u001b[A\n","Iteration:  75% 113/150 [01:12<00:24,  1.51it/s]\u001b[A\n","Iteration:  76% 114/150 [01:13<00:23,  1.51it/s]\u001b[A\n","Iteration:  77% 115/150 [01:13<00:23,  1.51it/s]\u001b[A\n","Iteration:  77% 116/150 [01:14<00:22,  1.51it/s]\u001b[A\n","Iteration:  78% 117/150 [01:15<00:21,  1.51it/s]\u001b[A\n","Iteration:  79% 118/150 [01:15<00:21,  1.50it/s]\u001b[A\n","Iteration:  79% 119/150 [01:16<00:20,  1.50it/s]\u001b[A\n","Iteration:  80% 120/150 [01:17<00:19,  1.50it/s]\u001b[A\n","Iteration:  81% 121/150 [01:17<00:19,  1.50it/s]\u001b[A\n","Iteration:  81% 122/150 [01:18<00:18,  1.50it/s]\u001b[A\n","Iteration:  82% 123/150 [01:19<00:18,  1.49it/s]\u001b[A\n","Iteration:  83% 124/150 [01:19<00:17,  1.49it/s]\u001b[A\n","Iteration:  83% 125/150 [01:20<00:16,  1.50it/s]\u001b[A\n","Iteration:  84% 126/150 [01:21<00:16,  1.49it/s]\u001b[A\n","Iteration:  85% 127/150 [01:21<00:15,  1.49it/s]\u001b[A\n","Iteration:  85% 128/150 [01:22<00:14,  1.49it/s]\u001b[A\n","Iteration:  86% 129/150 [01:23<00:14,  1.49it/s]\u001b[A\n","Iteration:  87% 130/150 [01:23<00:13,  1.49it/s]\u001b[A\n","Iteration:  87% 131/150 [01:24<00:12,  1.49it/s]\u001b[A\n","Iteration:  88% 132/150 [01:25<00:12,  1.49it/s]\u001b[A\n","Iteration:  89% 133/150 [01:25<00:11,  1.48it/s]\u001b[A\n","Iteration:  89% 134/150 [01:26<00:10,  1.48it/s]\u001b[A\n","Iteration:  90% 135/150 [01:27<00:10,  1.48it/s]\u001b[A\n","Iteration:  91% 136/150 [01:27<00:09,  1.47it/s]\u001b[A\n","Iteration:  91% 137/150 [01:28<00:08,  1.47it/s]\u001b[A\n","Iteration:  92% 138/150 [01:29<00:08,  1.47it/s]\u001b[A\n","Iteration:  93% 139/150 [01:29<00:07,  1.47it/s]\u001b[A\n","Iteration:  93% 140/150 [01:30<00:06,  1.46it/s]\u001b[A\n","Iteration:  94% 141/150 [01:31<00:06,  1.46it/s]\u001b[A\n","Iteration:  95% 142/150 [01:31<00:05,  1.46it/s]\u001b[A\n","Iteration:  95% 143/150 [01:32<00:04,  1.46it/s]\u001b[A\n","Iteration:  96% 144/150 [01:33<00:04,  1.46it/s]\u001b[A\n","Iteration:  97% 145/150 [01:33<00:03,  1.46it/s]\u001b[A\n","Iteration:  97% 146/150 [01:34<00:02,  1.46it/s]\u001b[A\n","Iteration:  98% 147/150 [01:35<00:02,  1.45it/s]\u001b[A\n","Iteration:  99% 148/150 [01:36<00:01,  1.45it/s]\u001b[A\n","Iteration:  99% 149/150 [01:36<00:00,  1.45it/s]\u001b[A\n","Iteration: 100% 150/150 [01:37<00:00,  1.54it/s]\n","Epoch:  33% 1/3 [01:37<03:14, 97.35s/it]\n","Iteration:   0% 0/150 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/150 [00:00<01:43,  1.43it/s]\u001b[A\n","Iteration:   1% 2/150 [00:01<01:43,  1.43it/s]\u001b[A\n","Iteration:   2% 3/150 [00:02<01:42,  1.43it/s]\u001b[A\n","Iteration:   3% 4/150 [00:02<01:42,  1.42it/s]\u001b[A\n","Iteration:   3% 5/150 [00:03<01:41,  1.42it/s]\u001b[A\n","Iteration:   4% 6/150 [00:04<01:41,  1.42it/s]\u001b[A\n","Iteration:   5% 7/150 [00:04<01:40,  1.42it/s]\u001b[A\n","Iteration:   5% 8/150 [00:05<01:40,  1.42it/s]\u001b[A\n","Iteration:   6% 9/150 [00:06<01:39,  1.42it/s]\u001b[A\n","Iteration:   7% 10/150 [00:07<01:38,  1.42it/s]\u001b[A\n","Iteration:   7% 11/150 [00:07<01:38,  1.42it/s]\u001b[A\n","Iteration:   8% 12/150 [00:08<01:37,  1.41it/s]\u001b[A\n","Iteration:   9% 13/150 [00:09<01:37,  1.41it/s]\u001b[A\n","Iteration:   9% 14/150 [00:09<01:36,  1.41it/s]\u001b[A\n","Iteration:  10% 15/150 [00:10<01:35,  1.41it/s]\u001b[A\n","Iteration:  11% 16/150 [00:11<01:35,  1.40it/s]\u001b[A\n","Iteration:  11% 17/150 [00:12<01:34,  1.41it/s]\u001b[A\n","Iteration:  12% 18/150 [00:12<01:33,  1.41it/s]\u001b[A\n","Iteration:  13% 19/150 [00:13<01:33,  1.40it/s]\u001b[A\n","Iteration:  13% 20/150 [00:14<01:32,  1.40it/s]\u001b[A\n","Iteration:  14% 21/150 [00:14<01:32,  1.40it/s]\u001b[A\n","Iteration:  15% 22/150 [00:15<01:31,  1.39it/s]\u001b[A\n","Iteration:  15% 23/150 [00:16<01:31,  1.39it/s]\u001b[A\n","Iteration:  16% 24/150 [00:17<01:30,  1.39it/s]\u001b[A\n","Iteration:  17% 25/150 [00:17<01:29,  1.39it/s]\u001b[A\n","Iteration:  17% 26/150 [00:18<01:29,  1.39it/s]\u001b[A\n","Iteration:  18% 27/150 [00:19<01:28,  1.39it/s]\u001b[A\n","Iteration:  19% 28/150 [00:19<01:28,  1.39it/s]\u001b[A\n","Iteration:  19% 29/150 [00:20<01:27,  1.38it/s]\u001b[A\n","Iteration:  20% 30/150 [00:21<01:26,  1.39it/s]\u001b[A\n","Iteration:  21% 31/150 [00:22<01:25,  1.38it/s]\u001b[A\n","Iteration:  21% 32/150 [00:22<01:25,  1.38it/s]\u001b[A\n","Iteration:  22% 33/150 [00:23<01:24,  1.38it/s]\u001b[A\n","Iteration:  23% 34/150 [00:24<01:23,  1.38it/s]\u001b[A\n","Iteration:  23% 35/150 [00:24<01:23,  1.39it/s]\u001b[A\n","Iteration:  24% 36/150 [00:25<01:22,  1.39it/s]\u001b[A\n","Iteration:  25% 37/150 [00:26<01:21,  1.39it/s]\u001b[A\n","Iteration:  25% 38/150 [00:27<01:20,  1.39it/s]\u001b[A\n","Iteration:  26% 39/150 [00:27<01:19,  1.39it/s]\u001b[A\n","Iteration:  27% 40/150 [00:28<01:19,  1.39it/s]\u001b[A\n","Iteration:  27% 41/150 [00:29<01:18,  1.40it/s]\u001b[A\n","Iteration:  28% 42/150 [00:29<01:17,  1.40it/s]\u001b[A\n","Iteration:  29% 43/150 [00:30<01:16,  1.41it/s]\u001b[A\n","Iteration:  29% 44/150 [00:31<01:15,  1.41it/s]\u001b[A\n","Iteration:  30% 45/150 [00:32<01:15,  1.40it/s]\u001b[A\n","Iteration:  31% 46/150 [00:32<01:14,  1.40it/s]\u001b[A\n","Iteration:  31% 47/150 [00:33<01:13,  1.40it/s]\u001b[A\n","Iteration:  32% 48/150 [00:34<01:12,  1.41it/s]\u001b[A\n","Iteration:  33% 49/150 [00:34<01:11,  1.41it/s]\u001b[A\n","Iteration:  33% 50/150 [00:35<01:10,  1.42it/s]\u001b[A\n","Iteration:  34% 51/150 [00:36<01:10,  1.41it/s]\u001b[A\n","Iteration:  35% 52/150 [00:37<01:09,  1.42it/s]\u001b[A\n","Iteration:  35% 53/150 [00:37<01:08,  1.42it/s]\u001b[A\n","Iteration:  36% 54/150 [00:38<01:07,  1.42it/s]\u001b[A\n","Iteration:  37% 55/150 [00:39<01:06,  1.42it/s]\u001b[A\n","Iteration:  37% 56/150 [00:39<01:06,  1.42it/s]\u001b[A\n","Iteration:  38% 57/150 [00:40<01:05,  1.43it/s]\u001b[A\n","Iteration:  39% 58/150 [00:41<01:04,  1.43it/s]\u001b[A\n","Iteration:  39% 59/150 [00:41<01:03,  1.43it/s]\u001b[A\n","Iteration:  40% 60/150 [00:42<01:02,  1.43it/s]\u001b[A\n","Iteration:  41% 61/150 [00:43<01:02,  1.43it/s]\u001b[A\n","Iteration:  41% 62/150 [00:44<01:01,  1.44it/s]\u001b[A\n","Iteration:  42% 63/150 [00:44<01:00,  1.44it/s]\u001b[A\n","Iteration:  43% 64/150 [00:45<00:59,  1.44it/s]\u001b[A\n","Iteration:  43% 65/150 [00:46<00:58,  1.45it/s]\u001b[A\n","Iteration:  44% 66/150 [00:46<00:58,  1.45it/s]\u001b[A\n","Iteration:  45% 67/150 [00:47<00:57,  1.45it/s]\u001b[A\n","Iteration:  45% 68/150 [00:48<00:56,  1.45it/s]\u001b[A\n","Iteration:  46% 69/150 [00:48<00:55,  1.45it/s]\u001b[A\n","Iteration:  47% 70/150 [00:49<00:55,  1.45it/s]\u001b[A\n","Iteration:  47% 71/150 [00:50<00:54,  1.45it/s]\u001b[A\n","Iteration:  48% 72/150 [00:50<00:53,  1.45it/s]\u001b[A\n","Iteration:  49% 73/150 [00:51<00:53,  1.45it/s]\u001b[A\n","Iteration:  49% 74/150 [00:52<00:52,  1.45it/s]\u001b[A\n","Iteration:  50% 75/150 [00:53<00:51,  1.45it/s]\u001b[A\n","Iteration:  51% 76/150 [00:53<00:50,  1.45it/s]\u001b[A\n","Iteration:  51% 77/150 [00:54<00:50,  1.46it/s]\u001b[A\n","Iteration:  52% 78/150 [00:55<00:49,  1.45it/s]\u001b[A\n","Iteration:  53% 79/150 [00:55<00:48,  1.46it/s]\u001b[A\n","Iteration:  53% 80/150 [00:56<00:48,  1.46it/s]\u001b[A\n","Iteration:  54% 81/150 [00:57<00:47,  1.46it/s]\u001b[A\n","Iteration:  55% 82/150 [00:57<00:46,  1.46it/s]\u001b[A\n","Iteration:  55% 83/150 [00:58<00:45,  1.46it/s]\u001b[A\n","Iteration:  56% 84/150 [00:59<00:45,  1.46it/s]\u001b[A\n","Iteration:  57% 85/150 [00:59<00:44,  1.46it/s]\u001b[A\n","Iteration:  57% 86/150 [01:00<00:43,  1.46it/s]\u001b[A\n","Iteration:  58% 87/150 [01:01<00:43,  1.46it/s]\u001b[A\n","Iteration:  59% 88/150 [01:01<00:42,  1.46it/s]\u001b[A\n","Iteration:  59% 89/150 [01:02<00:41,  1.46it/s]\u001b[A\n","Iteration:  60% 90/150 [01:03<00:41,  1.46it/s]\u001b[A\n","Iteration:  61% 91/150 [01:03<00:40,  1.46it/s]\u001b[A\n","Iteration:  61% 92/150 [01:04<00:39,  1.46it/s]\u001b[A\n","Iteration:  62% 93/150 [01:05<00:38,  1.46it/s]\u001b[A\n","Iteration:  63% 94/150 [01:06<00:38,  1.47it/s]\u001b[A\n","Iteration:  63% 95/150 [01:06<00:37,  1.46it/s]\u001b[A\n","Iteration:  64% 96/150 [01:07<00:36,  1.46it/s]\u001b[A\n","Iteration:  65% 97/150 [01:08<00:36,  1.46it/s]\u001b[A\n","Iteration:  65% 98/150 [01:08<00:37,  1.39it/s]\u001b[A\n","Iteration:  66% 99/150 [01:09<00:35,  1.42it/s]\u001b[A\n","Iteration:  67% 100/150 [01:10<00:35,  1.41it/s]\u001b[A\n","Iteration:  67% 101/150 [01:10<00:34,  1.42it/s]\u001b[A\n","Iteration:  68% 102/150 [01:11<00:33,  1.44it/s]\u001b[A\n","Iteration:  69% 103/150 [01:12<00:32,  1.44it/s]\u001b[A\n","Iteration:  69% 104/150 [01:13<00:32,  1.42it/s]\u001b[A\n","Iteration:  70% 105/150 [01:13<00:31,  1.43it/s]\u001b[A\n","Iteration:  71% 106/150 [01:14<00:31,  1.41it/s]\u001b[A\n","Iteration:  71% 107/150 [01:15<00:30,  1.41it/s]\u001b[A\n","Iteration:  72% 108/150 [01:15<00:29,  1.42it/s]\u001b[A\n","Iteration:  73% 109/150 [01:16<00:29,  1.41it/s]\u001b[A\n","Iteration:  73% 110/150 [01:17<00:28,  1.39it/s]\u001b[A\n","Iteration:  74% 111/150 [01:18<00:27,  1.40it/s]\u001b[A\n","Iteration:  75% 112/150 [01:18<00:27,  1.40it/s]\u001b[A\n","Iteration:  75% 113/150 [01:19<00:26,  1.40it/s]\u001b[A\n","Iteration:  76% 114/150 [01:20<00:25,  1.41it/s]\u001b[A\n","Iteration:  77% 115/150 [01:20<00:25,  1.37it/s]\u001b[A\n","Iteration:  77% 116/150 [01:21<00:24,  1.40it/s]\u001b[A\n","Iteration:  78% 117/150 [01:22<00:23,  1.40it/s]\u001b[A\n","Iteration:  79% 118/150 [01:23<00:22,  1.41it/s]\u001b[A\n","Iteration:  79% 119/150 [01:23<00:21,  1.42it/s]\u001b[A\n","Iteration:  80% 120/150 [01:24<00:21,  1.42it/s]\u001b[A\n","Iteration:  81% 121/150 [01:25<00:20,  1.43it/s]\u001b[A\n","Iteration:  81% 122/150 [01:25<00:19,  1.41it/s]\u001b[A\n","Iteration:  82% 123/150 [01:26<00:19,  1.42it/s]\u001b[A\n","Iteration:  83% 124/150 [01:27<00:18,  1.42it/s]\u001b[A\n","Iteration:  83% 125/150 [01:27<00:17,  1.42it/s]\u001b[A\n","Iteration:  84% 126/150 [01:28<00:16,  1.42it/s]\u001b[A\n","Iteration:  85% 127/150 [01:29<00:16,  1.42it/s]\u001b[A\n","Iteration:  85% 128/150 [01:30<00:15,  1.40it/s]\u001b[A\n","Iteration:  86% 129/150 [01:30<00:14,  1.41it/s]\u001b[A\n","Iteration:  87% 130/150 [01:31<00:14,  1.41it/s]\u001b[A\n","Iteration:  87% 131/150 [01:32<00:13,  1.41it/s]\u001b[A\n","Iteration:  88% 132/150 [01:32<00:12,  1.41it/s]\u001b[A\n","Iteration:  89% 133/150 [01:33<00:12,  1.38it/s]\u001b[A\n","Iteration:  89% 134/150 [01:34<00:11,  1.40it/s]\u001b[A\n","Iteration:  90% 135/150 [01:35<00:10,  1.39it/s]\u001b[A\n","Iteration:  91% 136/150 [01:35<00:10,  1.39it/s]\u001b[A\n","Iteration:  91% 137/150 [01:36<00:09,  1.40it/s]\u001b[A\n","Iteration:  92% 138/150 [01:37<00:08,  1.40it/s]\u001b[A\n","Iteration:  93% 139/150 [01:37<00:07,  1.39it/s]\u001b[A\n","Iteration:  93% 140/150 [01:38<00:07,  1.40it/s]\u001b[A\n","Iteration:  94% 141/150 [01:39<00:06,  1.39it/s]\u001b[A\n","Iteration:  95% 142/150 [01:40<00:05,  1.39it/s]\u001b[A\n","Iteration:  95% 143/150 [01:40<00:05,  1.40it/s]\u001b[A\n","Iteration:  96% 144/150 [01:41<00:04,  1.39it/s]\u001b[A\n","Iteration:  97% 145/150 [01:42<00:03,  1.39it/s]\u001b[A\n","Iteration:  97% 146/150 [01:42<00:02,  1.40it/s]\u001b[A\n","Iteration:  98% 147/150 [01:43<00:02,  1.40it/s]\u001b[A\n","Iteration:  99% 148/150 [01:44<00:01,  1.40it/s]\u001b[A\n","Iteration:  99% 149/150 [01:45<00:00,  1.40it/s]\u001b[A\n","Iteration: 100% 150/150 [01:45<00:00,  1.42it/s]\n","Epoch:  67% 2/3 [03:23<01:42, 102.30s/it]\n","Iteration:   0% 0/150 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/150 [00:00<01:44,  1.43it/s]\u001b[A\n","Iteration:   1% 2/150 [00:01<01:46,  1.38it/s]\u001b[A\n","Iteration:   2% 3/150 [00:02<01:46,  1.38it/s]\u001b[A\n","Iteration:   3% 4/150 [00:02<01:47,  1.36it/s]\u001b[A\n","Iteration:   3% 5/150 [00:03<01:45,  1.37it/s]\u001b[A\n","Iteration:   4% 6/150 [00:04<01:44,  1.37it/s]\u001b[A\n","Iteration:   5% 7/150 [00:05<01:43,  1.38it/s]\u001b[A\n","Iteration:   5% 8/150 [00:05<01:41,  1.40it/s]\u001b[A\n","Iteration:   6% 9/150 [00:06<01:40,  1.40it/s]\u001b[A\n","Iteration:   7% 10/150 [00:07<01:40,  1.40it/s]\u001b[A\n","Iteration:   7% 11/150 [00:07<01:39,  1.40it/s]\u001b[A\n","Iteration:   8% 12/150 [00:08<01:38,  1.40it/s]\u001b[A\n","Iteration:   9% 13/150 [00:09<01:38,  1.39it/s]\u001b[A\n","Iteration:   9% 14/150 [00:10<01:38,  1.38it/s]\u001b[A\n","Iteration:  10% 15/150 [00:10<01:38,  1.37it/s]\u001b[A\n","Iteration:  11% 16/150 [00:11<01:36,  1.38it/s]\u001b[A\n","Iteration:  11% 17/150 [00:12<01:35,  1.39it/s]\u001b[A\n","Iteration:  12% 18/150 [00:12<01:34,  1.39it/s]\u001b[A\n","Iteration:  13% 19/150 [00:13<01:33,  1.40it/s]\u001b[A\n","Iteration:  13% 20/150 [00:14<01:32,  1.40it/s]\u001b[A\n","Iteration:  14% 21/150 [00:15<01:31,  1.40it/s]\u001b[A\n","Iteration:  15% 22/150 [00:15<01:30,  1.41it/s]\u001b[A\n","Iteration:  15% 23/150 [00:16<01:30,  1.40it/s]\u001b[A\n","Iteration:  16% 24/150 [00:17<01:29,  1.41it/s]\u001b[A\n","Iteration:  17% 25/150 [00:18<01:31,  1.37it/s]\u001b[A\n","Iteration:  17% 26/150 [00:18<01:28,  1.40it/s]\u001b[A\n","Iteration:  18% 27/150 [00:19<01:28,  1.39it/s]\u001b[A\n","Iteration:  19% 28/150 [00:20<01:27,  1.39it/s]\u001b[A\n","Iteration:  19% 29/150 [00:20<01:26,  1.40it/s]\u001b[A\n","Iteration:  20% 30/150 [00:21<01:25,  1.40it/s]\u001b[A\n","Iteration:  21% 31/150 [00:22<01:24,  1.40it/s]\u001b[A\n","Iteration:  21% 32/150 [00:22<01:23,  1.40it/s]\u001b[A\n","Iteration:  22% 33/150 [00:23<01:23,  1.40it/s]\u001b[A\n","Iteration:  23% 34/150 [00:24<01:22,  1.41it/s]\u001b[A\n","Iteration:  23% 35/150 [00:25<01:21,  1.41it/s]\u001b[A\n","Iteration:  24% 36/150 [00:25<01:20,  1.41it/s]\u001b[A\n","Iteration:  25% 37/150 [00:26<01:19,  1.42it/s]\u001b[A\n","Iteration:  25% 38/150 [00:27<01:19,  1.42it/s]\u001b[A\n","Iteration:  26% 39/150 [00:27<01:19,  1.39it/s]\u001b[A\n","Iteration:  27% 40/150 [00:28<01:17,  1.41it/s]\u001b[A\n","Iteration:  27% 41/150 [00:29<01:17,  1.41it/s]\u001b[A\n","Iteration:  28% 42/150 [00:30<01:16,  1.41it/s]\u001b[A\n","Iteration:  29% 43/150 [00:30<01:15,  1.42it/s]\u001b[A\n","Iteration:  29% 44/150 [00:31<01:14,  1.41it/s]\u001b[A\n","Iteration:  30% 45/150 [00:32<01:14,  1.41it/s]\u001b[A\n","Iteration:  31% 46/150 [00:32<01:13,  1.41it/s]\u001b[A\n","Iteration:  31% 47/150 [00:33<01:12,  1.42it/s]\u001b[A\n","Iteration:  32% 48/150 [00:34<01:11,  1.42it/s]\u001b[A\n","Iteration:  33% 49/150 [00:34<01:11,  1.42it/s]\u001b[A\n","Iteration:  33% 50/150 [00:35<01:10,  1.42it/s]\u001b[A\n","Iteration:  34% 51/150 [00:36<01:09,  1.42it/s]\u001b[A\n","Iteration:  35% 52/150 [00:37<01:09,  1.42it/s]\u001b[A\n","Iteration:  35% 53/150 [00:37<01:08,  1.42it/s]\u001b[A\n","Iteration:  36% 54/150 [00:38<01:07,  1.42it/s]\u001b[A\n","Iteration:  37% 55/150 [00:39<01:06,  1.42it/s]\u001b[A\n","Iteration:  37% 56/150 [00:39<01:06,  1.42it/s]\u001b[A\n","Iteration:  38% 57/150 [00:40<01:05,  1.43it/s]\u001b[A\n","Iteration:  39% 58/150 [00:41<01:04,  1.42it/s]\u001b[A\n","Iteration:  39% 59/150 [00:42<01:03,  1.43it/s]\u001b[A\n","Iteration:  40% 60/150 [00:42<01:03,  1.43it/s]\u001b[A\n","Iteration:  41% 61/150 [00:43<01:02,  1.43it/s]\u001b[A\n","Iteration:  41% 62/150 [00:44<01:01,  1.43it/s]\u001b[A\n","Iteration:  42% 63/150 [00:44<01:01,  1.43it/s]\u001b[A\n","Iteration:  43% 64/150 [00:45<01:00,  1.43it/s]\u001b[A\n","Iteration:  43% 65/150 [00:46<00:59,  1.43it/s]\u001b[A\n","Iteration:  44% 66/150 [00:46<00:58,  1.43it/s]\u001b[A\n","Iteration:  45% 67/150 [00:47<00:58,  1.42it/s]\u001b[A\n","Iteration:  45% 68/150 [00:48<00:57,  1.42it/s]\u001b[A\n","Iteration:  46% 69/150 [00:49<00:56,  1.42it/s]\u001b[A\n","Iteration:  47% 70/150 [00:49<00:56,  1.42it/s]\u001b[A\n","Iteration:  47% 71/150 [00:50<00:55,  1.42it/s]\u001b[A\n","Iteration:  48% 72/150 [00:51<00:54,  1.43it/s]\u001b[A\n","Iteration:  49% 73/150 [00:51<00:53,  1.43it/s]\u001b[A\n","Iteration:  49% 74/150 [00:52<00:53,  1.43it/s]\u001b[A\n","Iteration:  50% 75/150 [00:53<00:52,  1.43it/s]\u001b[A\n","Iteration:  51% 76/150 [00:53<00:51,  1.43it/s]\u001b[A\n","Iteration:  51% 77/150 [00:54<00:51,  1.41it/s]\u001b[A\n","Iteration:  52% 78/150 [00:55<00:50,  1.42it/s]\u001b[A\n","Iteration:  53% 79/150 [00:56<00:49,  1.42it/s]\u001b[A\n","Iteration:  53% 80/150 [00:56<00:49,  1.42it/s]\u001b[A\n","Iteration:  54% 81/150 [00:57<00:48,  1.43it/s]\u001b[A\n","Iteration:  55% 82/150 [00:58<00:47,  1.43it/s]\u001b[A\n","Iteration:  55% 83/150 [00:58<00:46,  1.43it/s]\u001b[A\n","Iteration:  56% 84/150 [00:59<00:45,  1.44it/s]\u001b[A\n","Iteration:  57% 85/150 [01:00<00:45,  1.44it/s]\u001b[A\n","Iteration:  57% 86/150 [01:00<00:44,  1.44it/s]\u001b[A\n","Iteration:  58% 87/150 [01:01<00:43,  1.44it/s]\u001b[A\n","Iteration:  59% 88/150 [01:02<00:43,  1.44it/s]\u001b[A\n","Iteration:  59% 89/150 [01:03<00:42,  1.44it/s]\u001b[A\n","Iteration:  60% 90/150 [01:03<00:41,  1.44it/s]\u001b[A\n","Iteration:  61% 91/150 [01:04<00:41,  1.43it/s]\u001b[A\n","Iteration:  61% 92/150 [01:05<00:40,  1.43it/s]\u001b[A\n","Iteration:  62% 93/150 [01:05<00:39,  1.43it/s]\u001b[A\n","Iteration:  63% 94/150 [01:06<00:39,  1.43it/s]\u001b[A\n","Iteration:  63% 95/150 [01:07<00:38,  1.43it/s]\u001b[A\n","Iteration:  64% 96/150 [01:07<00:37,  1.44it/s]\u001b[A\n","Iteration:  65% 97/150 [01:08<00:36,  1.44it/s]\u001b[A\n","Iteration:  65% 98/150 [01:09<00:36,  1.43it/s]\u001b[A\n","Iteration:  66% 99/150 [01:09<00:35,  1.43it/s]\u001b[A\n","Iteration:  67% 100/150 [01:10<00:34,  1.43it/s]\u001b[A\n","Iteration:  67% 101/150 [01:11<00:34,  1.43it/s]\u001b[A\n","Iteration:  68% 102/150 [01:12<00:33,  1.43it/s]\u001b[A\n","Iteration:  69% 103/150 [01:12<00:33,  1.42it/s]\u001b[A\n","Iteration:  69% 104/150 [01:13<00:32,  1.43it/s]\u001b[A\n","Iteration:  70% 105/150 [01:14<00:31,  1.43it/s]\u001b[A\n","Iteration:  71% 106/150 [01:14<00:30,  1.42it/s]\u001b[A\n","Iteration:  71% 107/150 [01:15<00:30,  1.43it/s]\u001b[A\n","Iteration:  72% 108/150 [01:16<00:29,  1.43it/s]\u001b[A\n","Iteration:  73% 109/150 [01:16<00:28,  1.43it/s]\u001b[A\n","Iteration:  73% 110/150 [01:17<00:28,  1.43it/s]\u001b[A\n","Iteration:  74% 111/150 [01:18<00:27,  1.43it/s]\u001b[A\n","Iteration:  75% 112/150 [01:19<00:26,  1.43it/s]\u001b[A\n","Iteration:  75% 113/150 [01:19<00:25,  1.43it/s]\u001b[A\n","Iteration:  76% 114/150 [01:20<00:25,  1.43it/s]\u001b[A\n","Iteration:  77% 115/150 [01:21<00:24,  1.43it/s]\u001b[A\n","Iteration:  77% 116/150 [01:21<00:23,  1.42it/s]\u001b[A\n","Iteration:  78% 117/150 [01:22<00:23,  1.43it/s]\u001b[A\n","Iteration:  79% 118/150 [01:23<00:22,  1.42it/s]\u001b[A\n","Iteration:  79% 119/150 [01:24<00:21,  1.42it/s]\u001b[A\n","Iteration:  80% 120/150 [01:24<00:21,  1.43it/s]\u001b[A\n","Iteration:  81% 121/150 [01:25<00:20,  1.42it/s]\u001b[A\n","Iteration:  81% 122/150 [01:26<00:19,  1.42it/s]\u001b[A\n","Iteration:  82% 123/150 [01:26<00:18,  1.43it/s]\u001b[A\n","Iteration:  83% 124/150 [01:27<00:18,  1.42it/s]\u001b[A\n","Iteration:  83% 125/150 [01:28<00:17,  1.43it/s]\u001b[A\n","Iteration:  84% 126/150 [01:28<00:16,  1.42it/s]\u001b[A\n","Iteration:  85% 127/150 [01:29<00:16,  1.42it/s]\u001b[A\n","Iteration:  85% 128/150 [01:30<00:15,  1.42it/s]\u001b[A\n","Iteration:  86% 129/150 [01:31<00:14,  1.42it/s]\u001b[A\n","Iteration:  87% 130/150 [01:31<00:14,  1.42it/s]\u001b[A\n","Iteration:  87% 131/150 [01:32<00:13,  1.42it/s]\u001b[A\n","Iteration:  88% 132/150 [01:33<00:12,  1.42it/s]\u001b[A\n","Iteration:  89% 133/150 [01:33<00:11,  1.42it/s]\u001b[A\n","Iteration:  89% 134/150 [01:34<00:11,  1.42it/s]\u001b[A\n","Iteration:  90% 135/150 [01:35<00:10,  1.42it/s]\u001b[A\n","Iteration:  91% 136/150 [01:35<00:09,  1.42it/s]\u001b[A\n","Iteration:  91% 137/150 [01:36<00:09,  1.42it/s]\u001b[A\n","Iteration:  92% 138/150 [01:37<00:08,  1.42it/s]\u001b[A\n","Iteration:  93% 139/150 [01:38<00:07,  1.42it/s]\u001b[A\n","Iteration:  93% 140/150 [01:38<00:07,  1.42it/s]\u001b[A\n","Iteration:  94% 141/150 [01:39<00:06,  1.42it/s]\u001b[A\n","Iteration:  95% 142/150 [01:40<00:05,  1.42it/s]\u001b[A\n","Iteration:  95% 143/150 [01:40<00:04,  1.42it/s]\u001b[A\n","Iteration:  96% 144/150 [01:41<00:04,  1.42it/s]\u001b[A\n","Iteration:  97% 145/150 [01:42<00:03,  1.42it/s]\u001b[A\n","Iteration:  97% 146/150 [01:42<00:02,  1.42it/s]\u001b[A\n","Iteration:  98% 147/150 [01:43<00:02,  1.42it/s]\u001b[A\n","Iteration:  99% 148/150 [01:44<00:01,  1.42it/s]\u001b[A\n","Iteration:  99% 149/150 [01:45<00:00,  1.42it/s]\u001b[A\n","Iteration: 100% 150/150 [01:45<00:00,  1.42it/s]\n","Epoch: 100% 3/3 [05:08<00:00, 102.95s/it]\n","05/14/2022 05:17:13 - INFO - transformers.trainer -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","05/14/2022 05:17:13 - INFO - transformers.trainer -   Saving model checkpoint to ./output/${DATA}-${SPLIT}\n","05/14/2022 05:17:13 - INFO - transformers.configuration_utils -   Configuration saved in ./output/${DATA}-${SPLIT}/config.json\n","05/14/2022 05:17:19 - INFO - transformers.modeling_utils -   Model weights saved in ./output/${DATA}-${SPLIT}/pytorch_model.bin\n","05/14/2022 05:17:20 - INFO - root -   *** Test ***\n","05/14/2022 05:17:20 - INFO - transformers.trainer -   ***** Running Prediction *****\n","05/14/2022 05:17:20 - INFO - transformers.trainer -     Num examples = 534\n","05/14/2022 05:17:20 - INFO - transformers.trainer -     Batch size = 8\n","Prediction: 100% 67/67 [00:04<00:00, 14.68it/s]\n","05/14/2022 05:17:25 - INFO - __main__ -   ***** Test results sst-2 *****\n"]}],"source":["!python run_re.py \\\n","    --task_name SST-2 \\\n","    --config_name bert-base-cased \\\n","    --data_dir ${DATA_DIR} \\\n","    --model_name_or_path dmis-lab/biobert-base-cased-v1.1 \\\n","    --max_seq_length ${MAX_LENGTH} \\\n","    --num_train_epochs ${NUM_EPOCHS} \\\n","    --per_device_train_batch_size ${BATCH_SIZE} \\\n","    --save_steps ${SAVE_STEPS} \\\n","    --seed ${SEED} \\\n","    --do_train \\\n","    --do_predict \\\n","    --learning_rate 5e-5 \\\n","    --output_dir ${SAVE_DIR}/${ENTITY} \\\n","    --overwrite_output_dir"]},{"cell_type":"markdown","source":["######**Applying BioBERT for our Dataset**"],"metadata":{"id":"nLT_UHUSrnk6"}},{"cell_type":"code","source":["%env SAVE_DIR=./output/test\n","%env DATA=\"GAD\"\n","%env SPLIT=\"1\"\n","%env DATA_DIR=./testset\n","%env ENTITY=${DATA}-${SPLIT}\n","\n","%env MAX_LENGTH=128\n","%env BATCH_SIZE=32\n","%env NUM_EPOCHS=3\n","%env SAVE_STEPS=1000\n","%env SEED=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4H6uzK8fx7_9","executionInfo":{"status":"ok","timestamp":1652505522230,"user_tz":-330,"elapsed":460,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"bf511f2e-5c23-4475-d851-092c4291b0cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["env: SAVE_DIR=./output/test\n","env: DATA=\"GAD\"\n","env: SPLIT=\"1\"\n","env: DATA_DIR=./testset\n","env: ENTITY=${DATA}-${SPLIT}\n","env: MAX_LENGTH=128\n","env: BATCH_SIZE=32\n","env: NUM_EPOCHS=3\n","env: SAVE_STEPS=1000\n","env: SEED=1\n"]}]},{"cell_type":"code","source":["!python run_re.py --task_name SST-2 --config_name bert-base-cased --model_name_or_path dmis-lab/biobert-base-cased-v1.1 \\\n","        --do_predict --data_dir ${DATA_DIR} \\\n","        --output_dir ${SAVE_DIR} \\\n","        --overwrite_output_dir\n"],"metadata":{"id":"RIHwn6i3rt-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652505546600,"user_tz":-330,"elapsed":18204,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"c8bf7742-e042-4eaf-c911-50410ea0482f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["05/14/2022 05:18:53 - INFO - transformers.training_args -   PyTorch: setting up devices\n","05/14/2022 05:18:53 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/14/2022 05:18:53 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/config.json from cache at /root/.cache/torch/transformers/efc161c68d589c7960ab5463ed06a47d75d1ec73b2c31938de0ff797f76892dd.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n","05/14/2022 05:18:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","05/14/2022 05:18:53 - INFO - transformers.tokenization_utils_base -   Model name 'dmis-lab/biobert-base-cased-v1.1' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'dmis-lab/biobert-base-cased-v1.1' is a path, a model identifier, or url to a directory containing tokenizer files.\n","05/14/2022 05:18:54 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/vocab.txt from cache at /root/.cache/torch/transformers/a6d2d795bddbd9841e0ccd4a2f51c5b412116fda79488f6ffed7979e7ea9ef36.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","05/14/2022 05:18:54 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/added_tokens.json from cache at None\n","05/14/2022 05:18:54 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/special_tokens_map.json from cache at None\n","05/14/2022 05:18:54 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/tokenizer_config.json from cache at None\n","05/14/2022 05:18:54 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-base-cased-v1.1/tokenizer.json from cache at None\n","05/14/2022 05:18:54 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at ./testset\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   guid: test-1\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[101, 2496, 19012, 137, 5565, 109, 17157, 1149, 22922, 112, 2633, 20080, 3329, 112, 1884, 3842, 1116, 1107, 188, 27695, 137, 3653, 109, 118, 14755, 1111, 2357, 3673, 4182, 5182, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=None)\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   guid: test-2\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[101, 2496, 19012, 137, 5565, 109, 17157, 1149, 22922, 112, 2633, 20080, 3329, 112, 1884, 3842, 1116, 1107, 188, 27695, 2942, 10294, 6163, 189, 27226, 1116, 118, 14755, 1111, 2357, 3673, 137, 3653, 109, 5182, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=None)\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   guid: test-3\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[101, 2593, 1106, 137, 5565, 109, 118, 9271, 1103, 14543, 1905, 1107, 137, 3653, 109, 4420, 1144, 1151, 13870, 1193, 2628, 1114, 180, 11836, 5208, 118, 187, 2225, 113, 180, 118, 187, 2225, 114, 17895, 2781, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=None)\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   guid: test-4\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[101, 2593, 1106, 174, 1403, 2087, 1197, 118, 9271, 1103, 14543, 1905, 1107, 137, 3653, 109, 4420, 1144, 1151, 13870, 1193, 2628, 1114, 137, 5565, 109, 113, 180, 118, 187, 2225, 114, 17895, 2781, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=None)\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   guid: test-5\n","05/14/2022 05:18:54 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[101, 2593, 1106, 174, 1403, 2087, 1197, 118, 9271, 1103, 14543, 1905, 1107, 137, 3653, 109, 4420, 1144, 1151, 13870, 1193, 2628, 1114, 180, 11836, 5208, 118, 187, 2225, 113, 137, 5565, 109, 114, 17895, 2781, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=None)\n","05/14/2022 05:18:54 - INFO - transformers.data.datasets.glue -   Saving features into cached file ./testset/cached_test_BertTokenizer_128_sst-2 [took 0.051 s]\n","05/14/2022 05:18:54 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/test', overwrite_output_dir=True, do_train=False, do_eval=False, do_predict=True, evaluate_during_training=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/May14_05-18-52_b093b39aeb65', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, dataloader_drop_last=False)\n","05/14/2022 05:18:54 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","05/14/2022 05:18:54 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"sst-2\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","05/14/2022 05:18:54 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/dmis-lab/biobert-base-cased-v1.1/pytorch_model.bin from cache at /root/.cache/torch/transformers/685bf1692895fda434bf7c6a6eeab569b8b540cb6ba84268fc85fa13a1a7d748.7108af90c9002a82d12d4a007d2f2525c8d855c2bb9b10e701177769136bc7eb\n","05/14/2022 05:18:57 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","05/14/2022 05:18:57 - WARNING - transformers.modeling_utils -   Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","05/14/2022 05:19:02 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n","05/14/2022 05:19:03 - INFO - root -   *** Test ***\n","05/14/2022 05:19:03 - INFO - transformers.trainer -   ***** Running Prediction *****\n","05/14/2022 05:19:03 - INFO - transformers.trainer -     Num examples = 239\n","05/14/2022 05:19:03 - INFO - transformers.trainer -     Batch size = 8\n","Prediction: 100% 30/30 [00:01<00:00, 16.42it/s]\n","05/14/2022 05:19:05 - INFO - __main__ -   ***** Test results sst-2 *****\n"]}]},{"cell_type":"markdown","source":["######**Unmasking Bio Medical terms of interest**"],"metadata":{"id":"7dYJpBCRi7Ec"}},{"cell_type":"code","source":["original_sentences = pd.read_csv('pubtator_outputs/pub_original_sentences.tsv',sep='\\t')\n","predictions = pd.read_csv('output/test/test_results.txt', sep='\\t')\n","\n","final_re_output = pd.merge(original_sentences, predictions, on ='index', how='left')\n","final_re_output"],"metadata":{"id":"G2b1OfXHlD7d","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1652505683970,"user_tz":-330,"elapsed":386,"user":{"displayName":"18PD05 - BHARATHI A","userId":"15949479595575800654"}},"outputId":"fd065b7f-df7a-4e10-aed4-85949caad9ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     index                                           sentence  \\\n","0        0  Activating K-Ras mutations outwith 'hotspot' c...   \n","1        1  Activating K-Ras mutations outwith 'hotspot' c...   \n","2        2  Response to EGFR-targeted therapies in colorec...   \n","3        3  Response to EGFR-targeted therapies in colorec...   \n","4        4  Response to EGFR-targeted therapies in colorec...   \n","..     ...                                                ...   \n","216      6  Colorectal tumours (n=106) were screened for a...   \n","217      7  Four additional K-Ras mutations (Leu19Phe (1 o...   \n","218      8  We additionally identified a new K-Ras gene am...   \n","219      9  The identification of mutations outwith previo...   \n","220     10  A genetic model for colorectal cancer highligh...   \n","\n","               entity_1            entity_2  prediction  \n","0                 K-Ras  colorectal tumours           1  \n","1                 K-Ras              cancer           1  \n","2                  EGFR   colorectal cancer           0  \n","3     colorectal cancer         Kirsten-Ras           1  \n","4     colorectal cancer               K-Ras           0  \n","..                  ...                 ...         ...  \n","216  Colorectal tumours               K-Ras           1  \n","217               K-Ras             tumours           1  \n","218               K-Ras             tumours           1  \n","219               K-Ras  colorectal tumours           1  \n","220   colorectal cancer                 p53           1  \n","\n","[221 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-3c41e41a-f370-461f-8b2b-24cb79904f00\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>sentence</th>\n","      <th>entity_1</th>\n","      <th>entity_2</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Activating K-Ras mutations outwith 'hotspot' c...</td>\n","      <td>K-Ras</td>\n","      <td>colorectal tumours</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Activating K-Ras mutations outwith 'hotspot' c...</td>\n","      <td>K-Ras</td>\n","      <td>cancer</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Response to EGFR-targeted therapies in colorec...</td>\n","      <td>EGFR</td>\n","      <td>colorectal cancer</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Response to EGFR-targeted therapies in colorec...</td>\n","      <td>colorectal cancer</td>\n","      <td>Kirsten-Ras</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Response to EGFR-targeted therapies in colorec...</td>\n","      <td>colorectal cancer</td>\n","      <td>K-Ras</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>216</th>\n","      <td>6</td>\n","      <td>Colorectal tumours (n=106) were screened for a...</td>\n","      <td>Colorectal tumours</td>\n","      <td>K-Ras</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>217</th>\n","      <td>7</td>\n","      <td>Four additional K-Ras mutations (Leu19Phe (1 o...</td>\n","      <td>K-Ras</td>\n","      <td>tumours</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>218</th>\n","      <td>8</td>\n","      <td>We additionally identified a new K-Ras gene am...</td>\n","      <td>K-Ras</td>\n","      <td>tumours</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>219</th>\n","      <td>9</td>\n","      <td>The identification of mutations outwith previo...</td>\n","      <td>K-Ras</td>\n","      <td>colorectal tumours</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>10</td>\n","      <td>A genetic model for colorectal cancer highligh...</td>\n","      <td>colorectal cancer</td>\n","      <td>p53</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>221 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c41e41a-f370-461f-8b2b-24cb79904f00')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c41e41a-f370-461f-8b2b-24cb79904f00 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c41e41a-f370-461f-8b2b-24cb79904f00');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["final_re_output.to_csv('pubtator_outputs/final_relation_extraction_output.csv')"],"metadata":{"id":"08AuhcyAA1Cj"},"execution_count":null,"outputs":[]}]}